{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dfdc6",
   "metadata": {},
   "source": [
    "# Problem Set 3 (Deep Learning & Unsupervised Learning) Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784736c8",
   "metadata": {},
   "source": [
    "## Ling Min Hao "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7474a1",
   "metadata": {},
   "source": [
    "### 1. A Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46723a",
   "metadata": {},
   "source": [
    "(a) The neural network is formulated as follows (for one example): \n",
    "\n",
    "For the hidden layer, we have\n",
    "\\begin{align*}\n",
    "z_1^{[1]} = \\begin{bmatrix} w_{1,1}^{[1]} & w_{2,1}^{[1]} \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + w_{0,1}^{[1]} \\\\ \n",
    "h_1 = g(z_1^{[1]})\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "z_2^{[1]} = \\begin{bmatrix} w_{1,2}^{[1]} & w_{2,2}^{[1]} \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + w_{0,2}^{[1]} \\\\ \n",
    "h_2 = g(z_2^{[1]})\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "z_3^{[1]} = \\begin{bmatrix} w_{1,3}^{[1]} & w_{2,3}^{[1]} \\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + w_{0,3}^{[1]} \\\\ \n",
    "h_3 = g(z_3^{[1]})\n",
    "\\end{align*}\n",
    "\n",
    "For the output layer, we have \n",
    "\\begin{align*}\n",
    "z_1^{[2]} = \\begin{bmatrix} w_1^{[2]} & w_2^{[2]} & w_3^{[2]} \\end{bmatrix}\\begin{bmatrix} h_1 \\\\ h_2 \\\\ h_3 \\end{bmatrix} + w_0^{[2]} \\\\ \n",
    "o = g(z_1^{[2]})\n",
    "\\end{align*}\n",
    "\n",
    "We first solve the problem using one training example, i.e when \n",
    "\\begin{align*}\n",
    "l = (o-y)^2\n",
    "\\end{align*}\n",
    "\n",
    "Then \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial w_{1,2}^{[1]}}(o-y)^2 \n",
    "&= \\frac{\\partial}{\\partial w_{1,2}^{[1]}}(g(z_1^{[2]})-y)^2 \\\\\n",
    "&= \\frac{\\partial}{\\partial z_1^{[2]}}(g(z_1^{[2]})-y)^2\\frac{\\partial z_1^{[2]}}{\\partial h_2}\\frac{\\partial h_2}{\\partial z_2^{[1]}}\\frac{\\partial z_2^{[1]}}{\\partial w_{1,2}^{[1]}} \\\\ \n",
    "&= 2(g(z_1^{[2]})-y)g(z_1^{[2]})(1-g(z_1^{[2]}))w_2^{[2]}g(z_2^{[1]})(1-g(z_2^{[1]}))x_1 \\\\ \n",
    "&= 2(o-y)(o)(1-o)w_2^{[2]}h_2(1-h_2)e_1^Tx\n",
    "\\end{align*}\n",
    "\n",
    "where $$h_2 = g\\left(\\begin{bmatrix} w_{1,2}^{[1]} & w_{2,2}^{[1]} \\end{bmatrix}x + w_{0,2}^{[1]} \\right)$$\n",
    "\n",
    "For $m$ training examples, we have \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial l}{\\partial w_{1,2}^{[1]}} = \\frac{2}{m}\\sum_{i=1}^m(o^{(i)}-y^{(i)})(o^{(i)})(1-o^{(i)})w_2^{[2]}h_2^{(i)}(1-h_2^{(i)})e_1^Tx^{(i)}\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, the update rule is \n",
    "\\begin{align*}\n",
    "w_{1,2}^{[1]} := w_{1,2}^{[1]} - \\alpha\\left(\\frac{2}{m}\\sum_{i=1}^m(o^{(i)}-y^{(i)})(o^{(i)})(1-o^{(i)})w_2^{[2]}h_2^{(i)}(1-h_2^{(i)})e_1^Tx^{(i)}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cde08f",
   "metadata": {},
   "source": [
    "(b) We can see in Figure 1, the dataset can be perfectly classified by a triangle with boundaries $x_1 = 0.5$, $x_2 = 0.5$ and $x_1 + x_2 = 3.5$. \n",
    "\n",
    "First, we use three neurons to model three boundaries respectively. For example, we want to model decision boundary for $x_1 = 0.5$ using $h_1$ and $z_1^{[1]}$. Note that \n",
    "\n",
    "\\begin{align*}\n",
    "z_1^{[1]} = w_{1,1}^{[1]}x_1 + w_{2,1}^{[1]}x_2 + w_{0,1}^{[1]}\n",
    "\\end{align*}\n",
    "\n",
    "To obtain the decision boundary $x_1 = 0.5$, choose $w_{1,1}^{[1]} = -1$, $w_{2,1}^{[1]} = 0$, and $w_{0,1}^{[1]} = 0.5$. Then by definition of step function, an example is of class 1 if $h_1 = g(z_1^{[1]}) = -x_1 + 0.5 \\geq 0$ or equivalently, $x_1\\leq 0.5$. Otherwise, it is of class 0. \n",
    "\n",
    "Using similar argument on another two neurons (models), we choose $w_{1,2}^{[1]} = 0$, $w_{2,2}^{[1]} = -1$, and $w_{0,2}^{[1]} = 0.5$ for decision boundary $x_2 = 0.5$ and $w_{1,3}^{[1]} = 1$, $w_{2,3}^{[1]} = 1$, and $w_{0,3}^{[1]} = -3.5$ for decision boundary $x_1 + x_2 = 3.5$.\n",
    "\n",
    "Secondly, note that\n",
    "\\begin{align*}\n",
    "z_1^{[2]} &= w_1^{[2]}h_1 + w_2^{[2]}h_2 + w_3^{[2]}h_3 + w_0^{[2]}\\\\\n",
    "o &= g(z_1^{[2]})\n",
    "\\end{align*}\n",
    "\n",
    "We want to classify the examples as class 0 if they are inside the triangle ($h_1 = 0, h_2 = 0, h_3 = 0$), i.e we want\n",
    "\n",
    "$$z_1^{[2]} = w_1^{[2]}h_1 + w_2^{[2]}h_2 + w_3^{[2]}h_3 + w_0^{[2]} < 0$$ if $(h_1,h_2,h_3) = (0,0,0)$ and \n",
    "$$z_1^{[2]} = w_1^{[2]}h_1 + w_2^{[2]}h_2 + w_3^{[2]}h_3 + w_0^{[2]}\\geq 0 $$ otherwise. \n",
    "\n",
    "Choosing $w_0^{[2]} = -0.5$, $w_1^{[2]} = 1$, $w_2^{[2]} = 1$ and $w_3^{[2]} = 1$ fullfills the condition as the reader can verify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9d1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def example_weights():\n",
    "    \"\"\"This is an example function that returns weights.\n",
    "    Use this function as a template for optimal_step_weights and optimal_sigmoid_weights.\n",
    "    You do not need to modify this class for this assignment.\n",
    "    \"\"\"\n",
    "    w = {}\n",
    "\n",
    "    w['hidden_layer_0_1'] = 0\n",
    "    w['hidden_layer_1_1'] = 0\n",
    "    w['hidden_layer_2_1'] = 0\n",
    "    w['hidden_layer_0_2'] = 0\n",
    "    w['hidden_layer_1_2'] = 0\n",
    "    w['hidden_layer_2_2'] = 0\n",
    "    w['hidden_layer_0_3'] = 0\n",
    "    w['hidden_layer_1_3'] = 0\n",
    "    w['hidden_layer_2_3'] = 0\n",
    "\n",
    "    w['output_layer_0'] = 0\n",
    "    w['output_layer_1'] = 0\n",
    "    w['output_layer_2'] = 0\n",
    "    w['output_layer_3'] = 0\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def optimal_step_weights():\n",
    "    \"\"\"Return the optimal weights for the neural network with a step activation function.\n",
    "    \n",
    "    This function will not be graded if there are no optimal weights.\n",
    "    See the PDF for instructions on what each weight represents.\n",
    "    \n",
    "    The hidden layer weights are notated by [1] on the problem set and \n",
    "    the output layer weights are notated by [2].\n",
    "\n",
    "    This function should return a dict with elements for each weight, see example_weights above.\n",
    "\n",
    "    \"\"\"\n",
    "    w = example_weights()\n",
    "    # *** START CODE HERE ***\n",
    "    w['hidden_layer_0_1'] = 0.5\n",
    "    w['hidden_layer_1_1'] = -1\n",
    "    w['hidden_layer_2_1'] = 0\n",
    "    w['hidden_layer_0_2'] = 0.5\n",
    "    w['hidden_layer_1_2'] = 0\n",
    "    w['hidden_layer_2_2'] = -1\n",
    "    w['hidden_layer_0_3'] = -3.5\n",
    "    w['hidden_layer_1_3'] = 1\n",
    "    w['hidden_layer_2_3'] = 1\n",
    "\n",
    "    w['output_layer_0'] = -0.5\n",
    "    w['output_layer_1'] = 1\n",
    "    w['output_layer_2'] = 1\n",
    "    w['output_layer_3'] = 1\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a33bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_weights = optimal_step_weights()\n",
    "\n",
    "with open('output/step_weights', 'w') as f:\n",
    "    json.dump(step_weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e4043a",
   "metadata": {},
   "source": [
    "(c) If we impose $f(x) = x$ as the activation function for each neuron in the hidden layer, we have the output layer parameters given by \n",
    "\n",
    "\\begin{align*}\n",
    "z_1^{[2]} \n",
    "&= w_1^{[2]}h_1 + w_2{[2]}h_2 + w_3^{[2]}h_3 + w_0^{[2]} \\\\\n",
    "&=  w_1^{[2]}(w_{1,1}^{[1]}x_1 + w_{2,1}^{[1]}x_2 + w_{0,1}^{[1]}) + w_2{[2]}(w_{1,2}^{[1]}x_1 + w_{2,2}^{[1]}x_2 + w_{0,2}^{[1]}) + w_3^{[2]}(w_{1,3}^{[1]}x_1 + w_{2,3}^{[1]}x_2 + w_{0,3}^{[1]}) \n",
    "\\end{align*}\n",
    "\n",
    "which is a linear function. Thus, this neural network is a liner classifier. But the dataset is clearly not linearly seperable. So it is impossible to achieve $100\\%$ accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b5e93",
   "metadata": {},
   "source": [
    "### 2. KL divergence and Maximum Likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca91356",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63403472",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c650ee",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ecf197",
   "metadata": {},
   "source": [
    "### 3. KL Divergence, Fisher Information, and the Natural Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb758f",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b4884",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d22bf",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29303b9",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8d093",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2984d09",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccf98f",
   "metadata": {},
   "source": [
    "### 4. Semi-supervised EM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23e3d8",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d7f4e",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d64c3c",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8816e",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcadb7",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f4e8f",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9eea5",
   "metadata": {},
   "source": [
    "### 5. K-means for compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5bc2c",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8861a4c1",
   "metadata": {},
   "source": [
    "(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
